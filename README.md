# Multimodal Representations â€“ Exercise 3 (Group 11)

This repository contains our solutions for **Exercise 3** of the course on Multimodal Representations at TU Darmstadt.

## ğŸ“‚ Contents
- `E3.pdf` â€“ Original exercise sheet with task description  
- `E3_11.pdf` â€“ Our written group report (Group 11)  
- `E3_11.ipynb` â€“ Google Colab notebook with code and experiments  

## ğŸ‘¥ Authors
This work was completed as a **group assignment** by:  
- Mikael Alves Brito  
- Georg Matthes
- Viktor Maximilian Lehnhausen  

## ğŸ“ Description
The exercise focused on:
- Understanding **CLIP** (Contrastive Languageâ€“Image Pretraining)  
- Exploring **SigLIP** and **SigLiT**, and comparing them to CLIP  
- Implementing and correcting training functions for SigLIP  
- Zero-shot image classification with SigLIP  
- Fine-tuning SigLIP with both captions and templates  
- Analyzing the impact of hyperparameters (batch size, number of classes) on accuracy  
- Implementing and fine-tuning **SigLiT**, comparing its behavior to SigLIP  

## âš ï¸ Note
This project was created as part of a **university exercise sheet** and is **not individual work**.  
All results were prepared collaboratively by Group 11.  