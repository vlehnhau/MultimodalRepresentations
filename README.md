# Multimodal Representations – Exercise 3 (Group 11)

This repository contains our solutions for **Exercise 3** of the course on Multimodal Representations at TU Darmstadt.

## 📂 Contents
- `E3.pdf` – Original exercise sheet with task description  
- `E3_11.pdf` – Our written group report (Group 11)  
- `E3_11.ipynb` – Google Colab notebook with code and experiments  

## 👥 Authors
This work was completed as a **group assignment** by:  
- Mikael Alves Brito  
- Georg Matthes
- Viktor Maximilian Lehnhausen  

## 📝 Description
The exercise focused on:
- Understanding **CLIP** (Contrastive Language–Image Pretraining)  
- Exploring **SigLIP** and **SigLiT**, and comparing them to CLIP  
- Implementing and correcting training functions for SigLIP  
- Zero-shot image classification with SigLIP  
- Fine-tuning SigLIP with both captions and templates  
- Analyzing the impact of hyperparameters (batch size, number of classes) on accuracy  
- Implementing and fine-tuning **SigLiT**, comparing its behavior to SigLIP  

## ⚠️ Note
This project was created as part of a **university exercise sheet** and is **not individual work**.  
All results were prepared collaboratively by Group 11.  